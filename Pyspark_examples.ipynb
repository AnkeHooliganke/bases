{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "Pyspark_examples.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnkeHooliganke/bases/blob/main/Pyspark_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWSpIVT6Ium6"
      },
      "source": [
        "Часть примеров взята вот отсюда\n",
        "https://github.com/jadianes/spark-py-notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUSUS2ulIum-"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm72YEY0Ium_"
      },
      "source": [
        "# Creating a pyspark session \n",
        "that part + server setup is supposed to be managed by DE, I am not supposed to be doing that\n",
        "\n",
        "```\n",
        "Spark session is a unified entry point of a spark application from Spark 2.0. It provides a way to interact with various spark’s functionality with a lesser number of constructs. Instead of having a spark context, hive context, SQL context, now all of it is encapsulated in a Spark session.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHK1KTz7IunA"
      },
      "source": [
        "\n",
        "spark = SparkSession.builder \\\n",
        "                    .master(\"local\") \\\n",
        "                    .appName(\"MADE Pyspark Demo\") \\\n",
        "                    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "                    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN4sAjY-IunB"
      },
      "source": [
        "## Достали датасет\n",
        "\n",
        "Описание\n",
        "http://kdd.ics.uci.edu/databases/kddcup99/task.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-zgWUeIunB"
      },
      "source": [
        "!mkdir -p data\n",
        "f = urllib.request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\", \"data/kddcup.data_10_percent.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ybNFb2gIunC"
      },
      "source": [
        "## Деларируем чтение с диска -- реально пока ничего не делаем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWYyunuzIunC"
      },
      "source": [
        "data_file = \"data/kddcup.data_10_percent.gz\"\n",
        "raw_data = sc.textFile(data_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYRX_aJEIunD"
      },
      "source": [
        "## Вот тут датасет уже реально материалуизуется"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQ6sRVxIunD",
        "outputId": "5d2e76c5-cf2b-4952-92ee-ebb19b300dd1"
      },
      "source": [
        "raw_data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "494021"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiktqizrIunE",
        "outputId": "5105a545-5209-46b3-d8ce-76126eecde05"
      },
      "source": [
        "raw_data.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.',\n",
              " '0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,19,19,1.00,0.00,0.05,0.00,0.00,0.00,0.00,0.00,normal.',\n",
              " '0,tcp,http,SF,235,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,29,29,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.',\n",
              " '0,tcp,http,SF,219,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,6,0.00,0.00,0.00,0.00,1.00,0.00,0.00,39,39,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.',\n",
              " '0,tcp,http,SF,217,2032,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,6,0.00,0.00,0.00,0.00,1.00,0.00,0.00,49,49,1.00,0.00,0.02,0.00,0.00,0.00,0.00,0.00,normal.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd5s8vpzIunF"
      },
      "source": [
        "## Как фильтровать данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxwOsjHxIunF"
      },
      "source": [
        "normal_raw_data = raw_data.filter(lambda x: 'normal.' in x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ9S0kIqIunF",
        "outputId": "072392a4-6205-48f9-c43d-0bf6ed1a761b"
      },
      "source": [
        "from time import time\n",
        "t0 = time()\n",
        "normal_count = normal_raw_data.count()\n",
        "tt = time() - t0\n",
        "print(f\"There are {normal_count} 'normal' interactions\")\n",
        "print(f\"Count completed in {round(tt,3)} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 97278 'normal' interactions\n",
            "Count completed in 0.7 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQd8N9WJIunG"
      },
      "source": [
        "# Примеры с map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIXJuJKIIunG",
        "outputId": "5edf70fc-2e64-45ca-dd6f-037b21806123"
      },
      "source": [
        "from pprint import pprint\n",
        "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
        "t0 = time()\n",
        "head_rows = csv_data.take(5)\n",
        "tt = time() - t0\n",
        "print(f\"Parse completed in {round(tt,3)} seconds\")\n",
        "pprint(head_rows[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parse completed in 0.045 seconds\n",
            "['0',\n",
            " 'tcp',\n",
            " 'http',\n",
            " 'SF',\n",
            " '181',\n",
            " '5450',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '1',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '0',\n",
            " '8',\n",
            " '8',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '1.00',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '9',\n",
            " '9',\n",
            " '1.00',\n",
            " '0.00',\n",
            " '0.11',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '0.00',\n",
            " '0.00',\n",
            " 'normal.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8OIGN5FIunG",
        "outputId": "5dbbc918-4207-4d89-b5f9-c389b9933b7d"
      },
      "source": [
        "t0 = time()\n",
        "all_raw_data = raw_data.collect() # материализует датасет в памяти, подробнее: https://sparkbyexamples.com/pyspark/pyspark-collect/\n",
        "tt = time() - t0\n",
        "print(f\"Сollect completed in {round(tt,3)} seconds\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Сollect completed in 1.439 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Qpb51yIunH"
      },
      "source": [
        "# Примеры на агрегацию -- уже ближе к жизни\n",
        "Отсюда\n",
        "https://sparkbyexamples.com/pyspark/pyspark-aggregate-functions/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wSxWPDnIunH",
        "outputId": "cf0f44b8-a1d2-425c-f56e-a1b5eadf9c59"
      },
      "source": [
        "simpleData = [(\"James\", \"Sales\", 3000),\n",
        "    (\"Michael\", \"Sales\", 4600),\n",
        "    (\"Robert\", \"Sales\", 4100),\n",
        "    (\"Maria\", \"Finance\", 3000),\n",
        "    (\"James\", \"Sales\", 3000),\n",
        "    (\"Scott\", \"Finance\", 3300),\n",
        "    (\"Jen\", \"Finance\", 3900),\n",
        "    (\"Jeff\", \"Marketing\", 3000),\n",
        "    (\"Kumar\", \"Marketing\", 2000),\n",
        "    (\"Saif\", \"Sales\", 4100)\n",
        "  ]\n",
        "schema = [\"employee_name\", \"department\", \"salary\"]\n",
        "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- employee_name: string (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|James        |Sales     |3000  |\n",
            "|Michael      |Sales     |4600  |\n",
            "|Robert       |Sales     |4100  |\n",
            "|Maria        |Finance   |3000  |\n",
            "|James        |Sales     |3000  |\n",
            "|Scott        |Finance   |3300  |\n",
            "|Jen          |Finance   |3900  |\n",
            "|Jeff         |Marketing |3000  |\n",
            "|Kumar        |Marketing |2000  |\n",
            "|Saif         |Sales     |4100  |\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVVoPNG2IunH"
      },
      "source": [
        "from pyspark.sql.functions import approxCountDistinct, avg, collect_list, count, col"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gsma6QVsIunI",
        "outputId": "12a2185a-3ddf-405b-f8b5-adf1badc2c6a"
      },
      "source": [
        "# approx_count_distinct()\n",
        "print(f\"approx_count_distinct: {df.select(approxCountDistinct('salary')).collect()[0][0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "approx_count_distinct: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cVIv7d2IunI",
        "outputId": "6e9c3168-9ac5-4b58-cff5-bf61c0c7b933"
      },
      "source": [
        "print(f\"avg: {df.select(avg('salary')).collect()}\")\n",
        "# поэтому эти [0][0]\n",
        "print(f\"avg: {df.select(avg('salary')).collect()[0][0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "avg: [Row(avg(salary)=3400.0)]\n",
            "avg: 3400.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30ynIQmrIunI",
        "outputId": "a6f53c10-2a59-4fd3-f0c1-0883ddc06ec8"
      },
      "source": [
        "df.select(collect_list(\"salary\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------+\n",
            "|collect_list(salary)                                        |\n",
            "+------------------------------------------------------------+\n",
            "|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n",
            "+------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDXEVUS3IunJ",
        "outputId": "a1265d0b-4111-4602-943b-ab9fc726e10c"
      },
      "source": [
        "print(f\"count: {df.select(count('salary')).collect()[0][0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwkYZcqEIunJ"
      },
      "source": [
        "# Примеры c join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOvypfX4IunJ",
        "outputId": "f84dad74-180a-40a0-c241-793094513018"
      },
      "source": [
        "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
        "       (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
        "       (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
        "       (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
        "       (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
        "       (6,\"Brown\",2,\"2010\",\"50\",\"\",-1) \\\n",
        "       ]\n",
        "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
        "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
        "\n",
        "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
        "empDF.printSchema()\n",
        "empDF.show(truncate=False)\n",
        "\n",
        "dept = [(\"Finance\",10), \\\n",
        "        (\"Marketing\",20), \\\n",
        "        (\"Sales\",30), \\\n",
        "        (\"IT\",40) \\\n",
        "  ]\n",
        "deptColumns = [\"dept_name\",\"dept_id\"]\n",
        "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
        "deptDF.printSchema()\n",
        "deptDF.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- emp_id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- superior_emp_id: long (nullable = true)\n",
            " |-- year_joined: string (nullable = true)\n",
            " |-- emp_dept_id: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
            "+------+--------+---------------+-----------+-----------+------+------+\n",
            "\n",
            "root\n",
            " |-- dept_name: string (nullable = true)\n",
            " |-- dept_id: long (nullable = true)\n",
            "\n",
            "+---------+-------+\n",
            "|dept_name|dept_id|\n",
            "+---------+-------+\n",
            "|Finance  |10     |\n",
            "|Marketing|20     |\n",
            "|Sales    |30     |\n",
            "|IT       |40     |\n",
            "+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfhXGrLYIunJ"
      },
      "source": [
        "# Пример обычного join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHK8XnCWIunJ",
        "outputId": "eb3e6fc0-2cae-46d8-8ee2-8e076b110443"
      },
      "source": [
        "# df_left.join(df_right, <condition>, <join_type>)\n",
        "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"inner\") \\\n",
        "     .show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vzCkGJvIunK",
        "outputId": "b68ddeac-2a77-4f66-af16-a14748d3a568"
      },
      "source": [
        "empDF.join(deptDF, col(\"emp_dept_id\") == col(\"dept_id\"), \"inner\") \\\n",
        "     .show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxC9kfrqIunK"
      },
      "source": [
        "# Пример левого join\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_pLAnorIunK",
        "outputId": "370d8c6c-cd46-4fb4-a41e-bdc6b0d244d6"
      },
      "source": [
        "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"left\") \\\n",
        "     .show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG2GGNRHIunK"
      },
      "source": [
        "# Self join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C_Jot5mIunK",
        "outputId": "04fe136a-f4f2-4cf5-f319-67af55ecaccd"
      },
      "source": [
        "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"), col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"),\"inner\") \\\n",
        "     .select(col(\"emp1.emp_id\"),col(\"emp1.name\"), col(\"emp2.emp_id\").alias(\"superior_emp_id\"), col(\"emp2.name\").alias(\"superior_emp_name\")) \\\n",
        "     .show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+---------------+-----------------+\n",
            "|emp_id|name    |superior_emp_id|superior_emp_name|\n",
            "+------+--------+---------------+-----------------+\n",
            "|2     |Rose    |1              |Smith            |\n",
            "|3     |Williams|1              |Smith            |\n",
            "|4     |Jones   |2              |Rose             |\n",
            "|5     |Brown   |2              |Rose             |\n",
            "|6     |Brown   |2              |Rose             |\n",
            "+------+--------+---------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjRoObWpIunK"
      },
      "source": [
        "## Прям фигачим SQL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkjbbBRyIunK",
        "outputId": "6cd6d5ce-8573-44c8-ef4d-a4d99f3ae7ad"
      },
      "source": [
        "empDF.createOrReplaceTempView(\"EMP\")\n",
        "deptDF.createOrReplaceTempView(\"DEPT\")\n",
        "\n",
        "joinDF = spark.sql(\"select * from EMP e, DEPT d where e.emp_dept_id == d.dept_id\") \\\n",
        "  .show(truncate=False)\n",
        "\n",
        "joinDF2 = spark.sql(\"select * from EMP e INNER JOIN DEPT d ON e.emp_dept_id == d.dept_id\") \\\n",
        "  .show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
            "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
            "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
            "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
            "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
            "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}